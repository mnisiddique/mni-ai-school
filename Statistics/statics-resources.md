## 1. What to learn in foundation of descriptive statistics?

   1. Mean, median, mode
   2. Variance, standard deviation
   3. Percentiles, interquartile range
   4. Histograms, boxplots

## Why it matters:

    Need to understand data before modeling it. These tools helps exploring and cleaning data, detect outliers, and summarize datasets effectively.

## Resources:

   [Khan Academy: Descriptive Statistics](https://www.khanacademy.org/math/statistics-probability)
   Python: Use pandas.describe() or seaborn to visualize

## 2. What to learn in probability theory

   1. Probability rules (addition, multiplication)
   2. Conditional probability & Bayes’ theorem
   3. Independent vs dependent events
   4. Probability distributions (discrete & continuous)

## Why it matters:

   AI systems must make decisions under uncertainty. Understanding probability is vital for Bayesian models, Naive Bayes, and probabilistic reasoning.

## Resources:
   3Blue1Brown’s Visual Introduction to Probability (Link not availavle)
   Book: Think Stats by Allen B. Downey (freely available)
   [Introduction to probabiliy](https://www.youtube.com/watch?v=1uW3qMFA9Ho&list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6)


## 3. What to learn in probability distributions (for ML models)

   1. Discrete: Binomial, Poisson
   2. Continuous: Normal, Exponential
   3. PDFs, CDFs
   4. Central Limit Theorem

## Why it matters:

   Machine learning models (especially in NLP and generative AI) rely on distributions to model features and outputs. Understanding the Normal distribution is key for many estimators.

## Resources:

   StatQuest on YouTube (super beginner-friendly)
   SciPy library for hands-on coding

 ## 4. What to learn in inferential statistics

    1. Hypothesis testing (p-values, t-tests, z-tests)
    2. Confidence intervals
    3. Sampling distributions
    4. Statistical significance

## Why it matters:

   In AI experiments (A/B testing, model comparisons), you need to justify your decisions statistically and know when a result is meaningful.

## Resources:

   Khan Academy: [Inferential Stats](https://www.khanacademy.org/math/statistics-probability/inference)
   Python: statsmodels, scipy.stats

## 5. What to learn in regression and correlation

   1. Linear regression
   2. Correlation coefficients
   3. Residual analysis
   4. Multivariate regression

## Why it matters:

   Linear regression is the simplest ML model, and it’s a great starting point to learn about model fitting, overfitting, bias/variance tradeoff.

## Resources:

   [Coursera: Andrew Ng’s ML course](https://www.coursera.org/learn/machine-learning)
   Book: An Introduction to Statistical Learning (free online)

 ## 6. What to learn in bayesian thinking

    1. Bayes’ theorem (revisited)
    2. Priors, likelihood, posterior
    3. Bayesian inference
    4. MCMC basics (for advanced users)

## Why it matters:

    Bayesian models provide a powerful framework for uncertainty quantification, personalized predictions, and adaptive learning.

## Resources:

   Book: Bayesian Methods for Hackers (Jupyter notebook-based)
   YouTube: StatQuest’s [Bayes' Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM)

## 7. What to learn in statistical thinking in AI/ML

    1. Bias-variance tradeoff
    2. Overfitting vs underfitting
    3. Cross-validation
    4. Feature selection using statistical tests

## Why it matters:

    You’ll need statistics to evaluate models, tune hyperparameters, and choose the right algorithms.

## Resources:

   Hands-On ML with Scikit-Learn, Keras, and TensorFlow (by Aurélien Géron)
   sklearn.model_selection for practical coding


## Tools to Practice

   Python libraries: pandas, numpy, scipy, matplotlib, seaborn, statsmodels, sklearn
   Kaggle: Practice with real-world datasets

